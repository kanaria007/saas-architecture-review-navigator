# Is Your Schema Over-Normalizedâ€”or Just Not Thinking About It?

> Type: Structure  
> Category: Data  
> Audience: Engineers who haven't asked â€œwhat's the query cost of this join?â€

---

## âš–ï¸ This Isnâ€™t About Rules. Itâ€™s About Tradeoffs.

Normalization isnâ€™t â€œcorrect.â€  
Denormalization isnâ€™t â€œfast.â€

Theyâ€™re both **tools**â€”and every tool leaves scars.

---

## ğŸš¨ Common Failure Modes

- Over-normalized schema causes N+1 joins or multi-hop fetches  
- Denormalized tables drift out of sync  
- Analytics pipelines require rehydration of flattened data  
- Small updates touch many rows due to duplication

---

## âœ… Healthy Balance Looks Like:

- Normalize for source-of-truth and update frequency  
- Denormalize for read pathsâ€”**when latency matters more than purity**  
- Use materialized views or cache layers **with intentional ownership**  
- Keep the duplication cost visibleâ€”donâ€™t hide it in helper functions

---

## ğŸ§  Key Design Framing

Every duplication is a **sync contract**.  
Every join is a **latency tax**.  
You choose your poisonâ€”but own the symptoms.

---

## â“ FAQ

- **Q: Should we always denormalize for performance?**  
  **A:** No. But donâ€™t pretend joins are free.

- **Q: What if we need both forms?**  
  **A:** Then define the boundaryâ€”and who owns keeping them in sync.

---

## ğŸ”— Related Perspectives

- [ ] Schema-as-interface thinking  
- [ ] Read vs write path divergence  
- [ ] Data redundancy and synchronization risk  
